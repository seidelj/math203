\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {part}{I\hspace  {1em}Empirical Analysis 31000---Azeem Shaikh}{3}{part.1}}
\@writefile{toc}{\contentsline {chapter}{Probability preliminaries}{5}{chapter*.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{Set theory}{5}{section*.2}}
\@writefile{toc}{\contentsline {section}{Probability theory}{5}{section*.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Andrey Nikolaevich Kolmogorov. Respect.}}{6}{section*.3}}
\@writefile{toc}{\contentsline {section}{Inequalities}{6}{section*.4}}
\@writefile{toc}{\contentsline {section}{Conditional probability and independence}{7}{section*.5}}
\@writefile{toc}{\contentsline {section}{Random variables and distribution functions}{8}{section*.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces PDF of \(X \sim P = \mathcal  {N}(3, 1)\).}}{8}{section*.6}}
\@writefile{toc}{\contentsline {section}{Expectations and moments}{8}{section*.7}}
\@writefile{toc}{\contentsline {section}{Covariances and correlations}{10}{section*.8}}
\@writefile{toc}{\contentsline {chapter}{Large sample theory}{11}{chapter*.9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{Convergence in probability}{11}{section*.10}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Andrey Markov pondering his inequality.}}{12}{section*.10}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The moving average of \(X_i \sim \text  {Bernoulli}(0.3)\) drawn 1000 times and then replicated 25 times. Seems like the WLLN might be onto something.}}{13}{section*.10}}
\newpmemlabel{^_1}{14}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Johan Jensen in his later years.}}{14}{section*.10}}
\@writefile{toc}{\contentsline {section}{Convergence in distribution}{18}{section*.11}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces PDF of \(X \sim P = Exp\left (\frac  {1}{2}\right )\).}}{18}{section*.11}}
\@writefile{toc}{\contentsline {section}{Convergence in distribution and probability}{19}{section*.12}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Eugen Slutsky. Gotta respect that hair. Damn.}}{23}{Item.24}}
\newpmemlabel{^_2}{23}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Central Limit Theorem in action. Each panel plots the density of \(n\) observations of \(\mathaccentV {bar}416{X}_{100}\) 25 times, where \(X_i \sim \text  {Bernoulli}(0.3)\). Panel A has \(n = 10\). Panel B has \(n = 50\) and Panel C has \(n = 1000\). Looks pretty normal to me.}}{24}{Item.24}}
\@writefile{toc}{\contentsline {section}{Hypothesis testing}{25}{section*.13}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces R.A. Fisher looking like a huge nerd at a eugenics conference. Creepy. Anyways, Fisher's credited with the term ``test of significance.'' He also did a bunch of other useful stuff. Real bummer about the eugenics stuff, though.}}{25}{section*.13}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces William Sealy Gosset, AKA Student, looking a little schlitzed. E.L. Lehmann notes: The term ``studentization'' is a misnomer. The idea of replacing \(z_{1-\alpha }\) with \(t_{n-1, 1-\alpha }\) was already used by Laplace. Student's contribution was to work out the \emph  {exact} distribution in the one-sample situation.}}{26}{section*.13}}
\@writefile{toc}{\contentsline {section}{P-values}{28}{section*.14}}
\@writefile{toc}{\contentsline {section}{Delta method}{29}{section*.15}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Hold on! I have something for this.}}{29}{section*.15}}
\@writefile{toc}{\contentsline {section}{Confidence intervals}{33}{section*.16}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Jakob Bernoulli in all his snooty glory.}}{35}{section*.16}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Several vantage points of 1000 i.i.d. draws from \(\mathcal  {N}(\mu , \Sigma )\) in \(\PazoBB  {R}^3\). Sweeeeeet.}}{36}{section*.16}}
\@writefile{toc}{\contentsline {section}{Tightness}{37}{section*.17}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces ``We didn't say lose weight\dots  I might say tighten.''}}{37}{section*.17}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Yuri Vasilyevich Prokhorov. Known associate of Andrey Nikolaevich Kolmogorov.}}{38}{section*.17}}
\@writefile{toc}{\contentsline {section}{Stochastic order notation}{39}{section*.18}}
\@writefile{toc}{\contentsline {section}{Large sample theory Core questions}{40}{section*.19}}
\@writefile{toc}{\contentsline {subsection}{(a) Is \(\mathaccentV {hat}45E{\mu }_n\) an unbiased estimator of \(\mu \)? Justify your answer.}{40}{subsection*.20}}
\@writefile{toc}{\contentsline {subsection}{(b) Compute \(Var(\mathaccentV {hat}45E{\mu }_n)\). Is \(\mathaccentV {hat}45E{\mu }_n\) a consistent estimator of \(\mu \)? Justify your answer.}{40}{subsection*.21}}
\@writefile{toc}{\contentsline {subsection}{(c) Is \(\mathaccentV {hat}45E{\sigma }_i^2\) an unbiased estimator of \(\sigma _i^2\)? Justify your answer.}{41}{subsection*.22}}
\@writefile{toc}{\contentsline {subsection}{(d) Compute \(Var(\mathaccentV {hat}45E{\sigma }_i^2)\). Is \(\mathaccentV {hat}45E{\sigma }_i^2\) consistent? (Hint: If \(Z \sim \mathcal  {N}(0, \tau ^2)\) then \(E[Z^4] = 3\tau ^4\).)}{42}{subsection*.23}}
\@writefile{toc}{\contentsline {chapter}{Conditional expectations}{43}{chapter*.24}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{Linear Regression}{47}{chapter*.25}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{Linear regression with exogeneity assumption}{49}{section*.26}}
\@writefile{toc}{\contentsline {section}{Omitted variable bias}{51}{section*.27}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Figure 1 from Levitt (1997). Are police causing more crime to occur?}}{51}{section*.27}}
\@writefile{toc}{\contentsline {section}{Measurement error}{52}{section*.28}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Nate Silver possibly misinterpreting what a signal-to-noise ratio musses up.}}{52}{section*.28}}
\@writefile{toc}{\contentsline {section}{Estimating \(\beta \)}{53}{section*.29}}
\@writefile{toc}{\contentsline {section}{Projection interpretation of OLS}{54}{section*.30}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Ragnar Frisch of Frisch-Waugh-Lowell and Frisch labor supply elasticity fame.}}{54}{section*.30}}
\@writefile{toc}{\contentsline {section}{Measures of fit}{55}{section*.31}}
\@writefile{toc}{\contentsline {section}{Properties of OLS estimator}{57}{section*.32}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces I held back as long as possible. Without further adieu, ladies and gentleman, the main attraction: Carl Friedrich Gauss! ::crowd noises::}}{57}{section*.32}}
\@writefile{toc}{\contentsline {subsection}{Bias}{57}{subsection*.33}}
\@writefile{toc}{\contentsline {subsection}{Efficiency}{57}{subsection*.34}}
\@writefile{toc}{\contentsline {subsection}{Consistency}{58}{subsection*.35}}
\@writefile{toc}{\contentsline {subsection}{Limiting distribution of \(\mathaccentV {hat}45E{\beta }_n\)}{59}{subsection*.36}}
\@writefile{toc}{\contentsline {subsection}{Consistent estimation of \(\Omega \)}{59}{subsection*.37}}
\@writefile{toc}{\contentsline {section}{Inference}{61}{section*.38}}
\@writefile{toc}{\contentsline {chapter}{Instrumental variables}{65}{chapter*.39}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{Solving for \(\beta \)}{66}{section*.40}}
\@writefile{toc}{\contentsline {section}{Solving for subvectors of \(\beta \)}{69}{section*.41}}
\@writefile{toc}{\contentsline {section}{Estimating \(\beta \)}{70}{section*.42}}
\@writefile{toc}{\contentsline {section}{Properties of TSLS estimator}{72}{section*.43}}
\@writefile{toc}{\contentsline {section}{Weak insturments}{73}{section*.44}}
\@writefile{toc}{\contentsline {section}{Efficiency}{75}{section*.45}}
\@writefile{toc}{\contentsline {section}{Heterogeneity}{76}{section*.46}}
\@writefile{toc}{\contentsline {chapter}{Maximum Likelihood Estimation}{79}{chapter*.47}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{Unconditional Maximum Likelihood Estimators}{79}{section*.48}}
\@writefile{toc}{\contentsline {section}{Conditional ML Estimators}{81}{section*.49}}
\@writefile{toc}{\contentsline {section}{Properties of ML Estimators}{81}{section*.50}}
\@writefile{toc}{\contentsline {subsection}{Consistency}{82}{subsection*.51}}
\@writefile{toc}{\contentsline {section}{Mis-specification}{85}{section*.52}}
\@writefile{toc}{\contentsline {section}{Limiting distribution}{86}{section*.53}}
\@writefile{toc}{\contentsline {section}{Inference}{89}{section*.54}}
\@writefile{toc}{\contentsline {subsection}{Wald tests}{89}{subsection*.55}}
\@writefile{toc}{\contentsline {subsection}{Score tests}{89}{subsection*.56}}
\@writefile{toc}{\contentsline {subsection}{Likelihood ratio test}{90}{subsection*.57}}
\@writefile{toc}{\contentsline {part}{II\hspace  {1em}Empirical Analysis 31100---Harald Uhlig}{91}{part.2}}
\@writefile{toc}{\contentsline {chapter}{Measure Theory}{93}{chapter*.58}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{Measure Spaces}{93}{section*.59}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces An example of a measure space, \(\Omega \), with events, \(A_1\) and \(A_2\), and a measure, \(\mu \) that maps events to the real number line.}}{94}{Item.64}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Henri Lebesgue wearing an early prototype of Morpheus's sunglasses in the Matrix.}}{95}{Item.73}}
\@writefile{toc}{\contentsline {section}{Integration}{96}{section*.60}}
\@writefile{toc}{\contentsline {chapter}{Maximum Likelihood Estimation}{99}{chapter*.61}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{Framework}{99}{section*.62}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces The CDF of a logit and probit CDF are plotted. Additionally a Normal CDF with a slightly higher variance is plotted to show how to transform a Probit CDF to a Logit CDF.}}{100}{section*.62}}
\@writefile{toc}{\contentsline {section}{MLE, Score, and Information Matrix}{100}{section*.63}}
\@writefile{toc}{\contentsline {section}{Asymptotics}{102}{section*.64}}
\@writefile{toc}{\contentsline {section}{Three hypothesis tests}{103}{section*.65}}
\@writefile{toc}{\contentsline {chapter}{Extremum Estimators}{105}{chapter*.66}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{M-Estimators}{105}{subsection*.67}}
\@writefile{toc}{\contentsline {subsection}{GMM}{107}{subsection*.68}}
\@writefile{toc}{\contentsline {chapter}{Bayesian Inference}{111}{chapter*.69}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{Framework}{111}{section*.70}}
\@writefile{toc}{\contentsline {section}{Conjugacy and Priors}{114}{section*.71}}
\@writefile{toc}{\contentsline {section}{Numerical Methods for Bayesian Inference}{114}{section*.72}}
\ttl@finishall
